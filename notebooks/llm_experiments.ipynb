{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f73ef688-7a85-42c6-80be-df953cf29285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored  \n",
    "from pydantic import BaseModel  \n",
    "from typing import List, Optional, Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03f2f66-4a9b-4242-bf7d-65fcf3ad58e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMAFILE_BASE_URL = \"http://localhost:8080/v1\"\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "PERPLEXITY_BASE_URL = \"https://api.perplexity.ai\"\n",
    "GROQ_BASE_URL = \"https://api.groq.com/openai/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7bd5917",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_APY_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95e21068-06a8-447f-b87c-d5e2808b176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GROQ_MODEL = \"llama3-70b-8192\"\n",
    "OPENAI_MODEL = \"gpt4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e7c6dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query(BaseModel):\n",
    "    topic: str\n",
    "    query: str\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[Query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ece22d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tools(num:int, tool_type:str) -> list:\n",
    "    properties = {}\n",
    "    for i in range(1, num + 1):\n",
    "        key = f'{tool_type}_{i}'\n",
    "        properties[key] = {\n",
    "            'type': 'string',\n",
    "            'description': 'Search queries that would be useful for generating a report on my main topic'\n",
    "        }\n",
    "\n",
    "    custom_function = {\n",
    "        'name': 'generate_exa_search_queries',\n",
    "        'description': 'Generates Exa search queries to investigate the main topic',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': properties\n",
    "        },\n",
    "        'required': [f'{tool_type}_{i}' for i in range(1, num + 1)]\n",
    "    }\n",
    "\n",
    "    return [custom_function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a6bfebca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'generate_exa_search_queries',\n",
       "  'description': 'Generates Exa search queries to investigate the main topic',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'query_1': {'type': 'string',\n",
       "     'description': 'Search queries that would be useful for generating a report on my main topic'},\n",
       "    'query_2': {'type': 'string',\n",
       "     'description': 'Search queries that would be useful for generating a report on my main topic'},\n",
       "    'query_3': {'type': 'string',\n",
       "     'description': 'Search queries that would be useful for generating a report on my main topic'},\n",
       "    'query_4': {'type': 'string',\n",
       "     'description': 'Search queries that would be useful for generating a report on my main topic'},\n",
       "    'query_5': {'type': 'string',\n",
       "     'description': 'Search queries that would be useful for generating a report on my main topic'}}},\n",
       "  'required': ['query_1', 'query_2', 'query_3', 'query_4', 'query_5']}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = generate_tools(5, \"query\")\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "342cce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, tools=None, tool_choice=None, model=MODEL, provider=None):\n",
    "    try:\n",
    "        if provider.lower()==\"openai\":\n",
    "            print(colored(f\"Using OpenAI...\\n\", \"green\"))\n",
    "            client = OpenAI()\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                temperature=0,\n",
    "                stream=False,   \n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "                tool_choice=tool_choice,\n",
    "            )\n",
    "        else:\n",
    "            print(colored(f\"Using Groq...\\n\", \"green\"))\n",
    "            client = OpenAI(\n",
    "                api_key=GROQ_API_KEY,\n",
    "                base_url=GROQ_BASE_URL\n",
    "            )\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                temperature=0,\n",
    "                stream=False,\n",
    "                messages=messages,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dea3f935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_messages_and_tools(provider:str, topic:str, num_queries:int) -> list:\n",
    "    context = \"context\" if provider.lower()==\"openai\" else f\"provided schema: {json.dumps(Queries.model_json_schema(), indent=2)}\"\n",
    "    messages =[\n",
    "        {\"role\": \"system\", \"content\": f\"You are the world's most advanced and intelligent programming and AI Research assistant that can only be queried via an API. Based on the tools and schemas provided to you and in your arsenal, you generate the most accurate and optimized JSON responses based on the {context}.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"I'm going to give you a topic I want to research. I want you to generate {num_queries} interesting, diverse search queries that would be useful for generating a report on my main topic. Here is the main topic: {topic}.\"}\n",
    "    ]\n",
    "    tools = generate_tools(num_queries, \"query\")\n",
    "    tool_choice = {\"type\": \"function\", \"function\": {\"name\": tools[0]['name']}}\n",
    "    return messages, tools, tool_choice\n",
    "\n",
    "def get_completion_args(provider:str, topic:str) -> Dict:\n",
    "    messages, tools, tool_choice = get_messages_and_tools(provider, topic, num_queries)\n",
    "    return {\n",
    "        \"messages\": messages,\n",
    "        \"tools\": tools,\n",
    "        \"tool_choice\": tool_choice,\n",
    "        \"provider\": provider,\n",
    "        \"model\": OPENAI_MODEL if provider.lower()==\"openai\" else GROQ_MODEL,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d12ed28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUsing Groq...\n",
      "\u001b[0m\n",
      "{\n",
      "  \"queries\": [\n",
      "    {\n",
      "      \"topic\": \"LLM Evaluation\",\n",
      "      \"query\": \"What are the benefits and limitations of using a panel of LLM judges to evaluate the correctness of another LLM?\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"LLM Evaluation Metrics\",\n",
      "      \"query\": \"What metrics can be used to evaluate the correctness of an LLM, and how can a panel of LLM judges be used to improve the evaluation process?\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"LLM Evaluation Methods\",\n",
      "      \"query\": \"What are the different methods for evaluating the correctness of an LLM, and how does using a panel of LLM judges compare to other methods?\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"LLM Judge Agreement\",\n",
      "      \"query\": \"How can the agreement between a panel of LLM judges be measured and improved, and what are the implications for evaluating the correctness of another LLM?\"\n",
      "    },\n",
      "    {\n",
      "      \"topic\": \"LLM Evaluation Bias\",\n",
      "      \"query\": \"How can bias be mitigated when using a panel of LLM judges to evaluate the correctness of another LLM, and what are the potential sources of bias in this process?\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "groq_args = get_completion_args(provider=\"groq\", topic = \"Using a panel of LLM judges to evaluate the correctness of another LLM\")\n",
    "groq_res = chat_completion_request(**groq_args)\n",
    "print(json.dumps(json.loads(groq_res.choices[0].message.content), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "280cfad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUsing OpenAI...\n",
      "\u001b[0m\n",
      "Unable to generate ChatCompletion response\n",
      "Exception: Error code: 404 - {'error': {'message': 'The model `gpt4o` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NotFoundError' object has no attribute 'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m oai_args \u001b[38;5;241m=\u001b[39m get_completion_args(provider\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m\"\u001b[39m, topic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a panel of LLM judges to evaluate the correctness of another LLM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m oai_res \u001b[38;5;241m=\u001b[39m chat_completion_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moai_args)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(json\u001b[38;5;241m.\u001b[39mloads(\u001b[43moai_res\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent), indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NotFoundError' object has no attribute 'choices'"
     ]
    }
   ],
   "source": [
    "oai_args = get_completion_args(provider=\"openai\", topic = \"Using a panel of LLM judges to evaluate the correctness of another LLM\")\n",
    "oai_res = chat_completion_request(**oai_args)\n",
    "print(json.dumps(json.loads(oai_res.choices[0].message.content), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "623bca55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Query(topic='LLM Evaluation', query='What are the benefits and limitations of using a panel of LLM judges to evaluate the correctness of another LLM?'),\n",
       " Query(topic='LLM Evaluation Metrics', query='What metrics can be used to evaluate the correctness of an LLM, and how can a panel of LLM judges be used to improve the evaluation process?'),\n",
       " Query(topic='LLM Evaluation Methods', query='What are the different methods for evaluating the correctness of an LLM, and how does using a panel of LLM judges compare to other methods?'),\n",
       " Query(topic='LLM Judge Agreement', query='How can the agreement between a panel of LLM judges be measured and improved, and what are the implications for evaluating the correctness of another LLM?'),\n",
       " Query(topic='LLM Evaluation Bias', query='How can bias be mitigated when using a panel of LLM judges to evaluate the correctness of another LLM, and what are the potential sources of bias in this process?')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Queries.model_validate_json(res.choices[0].message.content)\n",
    "model.queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97487e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2b9008e-26b4-46dc-ba3a-a6deebe21b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tech industry is concentrated in the Bay Area, specifically in Silicon Valley, for a combination of historical, cultural, and economic reasons:\n",
      "\n",
      "1. **Early innovation**: The Bay Area has a long history of innovation, dating back to the 1950s and 1960s, when the first electronics and computer companies were established. This early start gave the region a head start in developing a tech ecosystem.\n",
      "2. **Stanford University**: Stanford University, located in the heart of Silicon Valley, has played a significant role in the region's tech growth. The university's entrepreneurial spirit, research focus, and talent pool have contributed to the area's tech dominance.\n",
      "3. ** Defense and aerospace industry**: During the Cold War era, the Bay Area became a hub for defense and aerospace industries, which laid the groundwork for the region's expertise in electronics and computer technology.\n",
      "4. **Venture capital**: The Bay Area is home to a high concentration of venture capital firms, which provide essential funding for startups and early-stage companies. This access to capital has enabled entrepreneurs to take risks and pursue innovative ideas.\n",
      "5. **Network effects**: As more tech companies and talent clusters formed in the Bay Area, a network effect took hold. Companies wanted to be near their customers, suppliers, and partners, which created a snowball effect, attracting even more companies and talent to the region.\n",
      "6. **Mild climate and quality of life**: The Bay Area's mild climate, natural beauty, and high standard of living have made it an attractive location for entrepreneurs, engineers, and professionals, encouraging them to stay and build their careers in the region.\n",
      "7. **Government support**: Local and state governments have implemented policies to support the growth of the tech industry, such as tax incentives, business-friendly regulations, and investment in infrastructure.\n",
      "8. **Talent pool**: The Bay Area is home to a large pool of skilled engineers, programmers, and entrepreneurs, which has created a self-sustaining ecosystem. Top universities, such as Stanford and the University of California, Berkeley, provide a steady supply of talented graduates.\n",
      "9. **Culture of innovation**: The Bay Area has a culture that encourages experimentation, risk-taking, and innovation. This mindset has fostered a community that supports and celebrates entrepreneurship and technological advancement.\n",
      "10. **Path dependency**: The Bay Area's early start in the tech industry created a path dependency, where the region's existing infrastructure, expertise, and networks have made it easier for new companies to emerge and succeed.\n",
      "\n",
      "These factors have combined to make the Bay Area, particularly Silicon Valley, a global hub for the tech industry. While other regions have tried to replicate this success, the Bay Area's unique combination of history, culture, and infrastructure has made it a difficult environment to replicate.None"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are ChatGPT, an AI assistant. Your top priority is achieving user fulfillment via helping them with their requests and being concise as possible.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Why is the tech industry concentrated in the Bay Area?\"}\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc1a4bb-473b-4513-9578-bcc6590b2ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
