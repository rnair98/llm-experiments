{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c466bc5a-5fd9-4bdc-97fa-36242c1c59f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq openai scipy tenacity tiktoken termcolor arxiv polars duckdb PyPDF2 tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85cefc89-91f8-4b83-959f-d92b1e3ef4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_MODEL = \"gpt-4o\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "SYSTEM = \"You are a helpful assistant.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc7e039c-ecca-47d3-a995-94efcea6683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import arxiv\n",
    "import ast\n",
    "import concurrent\n",
    "import json\n",
    "import os\n",
    "import polars as pl\n",
    "import duckdb\n",
    "import tiktoken\n",
    "from csv import writer\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from duckdb import DuckDBPyConnection\n",
    "from openai import OpenAI\n",
    "from PyPDF2 import PdfReader\n",
    "from scipy import spatial\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored\n",
    "from typing import List,Dict,Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bee38ed1-a752-49f2-89f5-7e1a1967e541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory './papers' already exists.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./papers'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = './papers'\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    print(f\"Directory '{directory}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "data_dir = os.path.join(os.curdir,\"papers\")\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f706b4ed-4318-4ff7-8953-84f2be25f7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"ask_database\",\n",
    "            \"description\": \"Use this function to answer user questions. Input should be a fully formed SQL query.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": f\"\"\"\n",
    "                                SQL query extracting info to answer the user's question.\n",
    "                                SQL should be written using this database schema:\n",
    "                                {database_schema_string}\n",
    "                                The query should be returned in plain text, not in JSON.\n",
    "                                \"\"\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17d7519-95ef-4649-b425-0ecb0385704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "#client = instructor.from_openai(OpenAI())\n",
    "\n",
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(\n",
    "        messages:List[Dict[str,Any]]=None, \n",
    "        tools:List[Dict[str,Any]]=None, \n",
    "        tool_choice=None, \n",
    "        model:str=MODEL\n",
    "):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=tool_choice,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n",
    "\n",
    "def pretty_print_conversation(messages:List[Dict[str,Any]]=None):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "    \n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c86c1f6-235a-4870-a8fc-892bf3a2ca2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method create in module openai.resources.chat.completions:\n",
      "\n",
      "create(*, messages: 'Iterable[ChatCompletionMessageParam]', model: 'Union[str, ChatModel]', frequency_penalty: 'Optional[float] | NotGiven' = NOT_GIVEN, function_call: 'completion_create_params.FunctionCall | NotGiven' = NOT_GIVEN, functions: 'Iterable[completion_create_params.Function] | NotGiven' = NOT_GIVEN, logit_bias: 'Optional[Dict[str, int]] | NotGiven' = NOT_GIVEN, logprobs: 'Optional[bool] | NotGiven' = NOT_GIVEN, max_tokens: 'Optional[int] | NotGiven' = NOT_GIVEN, n: 'Optional[int] | NotGiven' = NOT_GIVEN, presence_penalty: 'Optional[float] | NotGiven' = NOT_GIVEN, response_format: 'completion_create_params.ResponseFormat | NotGiven' = NOT_GIVEN, seed: 'Optional[int] | NotGiven' = NOT_GIVEN, stop: 'Union[Optional[str], List[str]] | NotGiven' = NOT_GIVEN, stream: 'Optional[Literal[False]] | Literal[True] | NotGiven' = NOT_GIVEN, stream_options: 'Optional[ChatCompletionStreamOptionsParam] | NotGiven' = NOT_GIVEN, temperature: 'Optional[float] | NotGiven' = NOT_GIVEN, tool_choice: 'ChatCompletionToolChoiceOptionParam | NotGiven' = NOT_GIVEN, tools: 'Iterable[ChatCompletionToolParam] | NotGiven' = NOT_GIVEN, top_logprobs: 'Optional[int] | NotGiven' = NOT_GIVEN, top_p: 'Optional[float] | NotGiven' = NOT_GIVEN, user: 'str | NotGiven' = NOT_GIVEN, extra_headers: 'Headers | None' = None, extra_query: 'Query | None' = None, extra_body: 'Body | None' = None, timeout: 'float | httpx.Timeout | None | NotGiven' = NOT_GIVEN) -> 'ChatCompletion | Stream[ChatCompletionChunk]' method of openai.resources.chat.completions.Completions instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(OpenAI().chat.completions.create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e282be1b-71a3-4aed-8015-c265e312cee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
